
[DEFAULT]
# ログファイル名
logger = log
# 用いるGPU 番号
cuda = 0
# 10分割したうちの何番目を用いるか.. if data size is too huge, we segment time steps into 10 parts, . If the value is N (0<=N<=9), we use (N+1)th time section.
use_segment = 0
# エポック数
n_epoch = 350
# 分割サイズ (データをsplit_sizeフレームごとに分割）
split_size = 2000
# バッチサイズ (学習の1回の更新で使う分割データの個数)
batch_size = 64
# 入力次元数（ニューロンの数）
dim_input = 128
# トレインに使うデータの割合  train(50%) vali(20%) test(30%) for pre-training within training data.
train_rate = 0.5
# バリデーション
valid_rate = 0.2


[path]
base = ./
spike = ../data/128neuron_rep1/Group2LOV201201001_LOV201201001/LOV201201001/split_spikes.npy
result = ../data/128neuron_rep1/Group2LOV201201001_LOV201201001/LOV201201001/128_128_128_gamma002_epo350

# データファイル
# 結果を入れるディレクトリ

[lstm]
n_lstm_hidden = 128
batch_size = 5

[lstm_stack]
gamma = 0.02
# Focal lossの重み係数。gamma=0の場合はbinary cross entropyに一致する。
n_layer_list = 1,1,1
# LSTMの隠れ層の数（リスト）。
n_hidden_list = 128,128,128
# この場合は、（入力層->）ユニット数128次元のLSTM 1層、64次元のLSTM 2層、256次元のLSTM 3層（->線形層、softmax->出力層）
batch_size = 5
# バッチサイズ（上書き）
